{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "UtcXOXsZB1OU",
      "metadata": {
        "id": "UtcXOXsZB1OU"
      },
      "source": [
        "# Chess Sim2Real — **Ready-to-run inference** (Real photo → predicted FEN → synthetic board image)\n",
        "\n",
        "This notebook is **self‑contained** (no missing globals).  \n",
        "**Inputs:** a real chess image + your trained `.pt` checkpoint.  \n",
        "**Outputs:** predicted FEN placement + a rendered synthetic chessboard image of the predicted state.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5ZQhttJnB1OV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZQhttJnB1OV",
        "outputId": "a4bc98e7-732f-49f9-c6b0-ed3b7dc36663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/6.1 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install albumentations python-chess cairosvg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "oIgt5DbjB1OW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIgt5DbjB1OW",
        "outputId": "a175bbb4-a459-4e0e-fab5-30bf10db1cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, io, math, random\n",
        "from pathlib import Path\n",
        "import cv2, numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import chess\n",
        "import chess.svg\n",
        "import cairosvg\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from google.colab import files\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "x0uJROGzB1OW",
      "metadata": {
        "id": "x0uJROGzB1OW"
      },
      "outputs": [],
      "source": [
        "CLASSES = [\"empty\",\"wP\",\"wN\",\"wB\",\"wR\",\"wQ\",\"wK\",\"bP\",\"bN\",\"bB\",\"bR\",\"bQ\",\"bK\"]\n",
        "\n",
        "IDX2FEN = {\n",
        "    0: None,\n",
        "    1: \"P\", 2:\"N\", 3:\"B\", 4:\"R\", 5:\"Q\", 6:\"K\",\n",
        "    7: \"p\", 8:\"n\", 9:\"b\", 10:\"r\", 11:\"q\", 12:\"k\"\n",
        "}\n",
        "\n",
        "def grid_to_fen_placement(grid_idx: np.ndarray) -> str:\n",
        "    rows = []\n",
        "    for r in range(8):\n",
        "        run = 0\n",
        "        out = \"\"\n",
        "        for c in range(8):\n",
        "            ch = IDX2FEN.get(int(grid_idx[r,c]), None)\n",
        "            if ch is None:\n",
        "                run += 1\n",
        "            else:\n",
        "                if run:\n",
        "                    out += str(run)\n",
        "                    run = 0\n",
        "                out += ch\n",
        "        if run:\n",
        "            out += str(run)\n",
        "        rows.append(out)\n",
        "    return \"/\".join(rows)\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "zf95g4oGELWS",
      "metadata": {
        "id": "zf95g4oGELWS"
      },
      "outputs": [],
      "source": [
        "class SquareClassifier(nn.Module):\n",
        "    def __init__(self, num_classes: int, dropout: float = 0.2, backbone: str = \"resnet18\"):\n",
        "        super().__init__()\n",
        "        net = torchvision.models.resnet34(weights=None) if backbone == \"resnet34\" else torchvision.models.resnet18(weights=None)\n",
        "        in_features = net.fc.in_features\n",
        "        net.fc = nn.Sequential(nn.Dropout(dropout), nn.Linear(in_features, num_classes))\n",
        "        self.net = net\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class EfficientNetSquareClassifier(nn.Module):\n",
        "    def __init__(self, num_classes: int, dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        net = torchvision.models.efficientnet_b0(weights=None)\n",
        "        in_features = net.classifier[1].in_features\n",
        "        net.classifier[1] = nn.Sequential(nn.Dropout(dropout), nn.Linear(in_features, num_classes))\n",
        "        self.net = net\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def infer_model_type_from_state_dict(sd: dict) -> str:\n",
        "    keys = list(sd.keys())\n",
        "    if any(k.startswith(\"net.layer1.\") or k.startswith(\"net.conv1.\") for k in keys) or any(\".layer1.\" in k for k in keys):\n",
        "        return \"resnet\"\n",
        "    if any(k.startswith(\"net.features.\") for k in keys) or any(\".features.\" in k for k in keys):\n",
        "        return \"efficientnet\"\n",
        "    return \"unknown\"\n",
        "\n",
        "def load_checkpoint_flexible(path: str, num_classes: int) -> nn.Module:\n",
        "    ckpt = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
        "    sd = ckpt[\"model_state\"] if isinstance(ckpt, dict) and \"model_state\" in ckpt else ckpt\n",
        "    drop = float(ckpt.get(\"cfg\", {}).get(\"dropout\", 0.2)) if isinstance(ckpt, dict) else 0.2\n",
        "\n",
        "    mtype = infer_model_type_from_state_dict(sd)\n",
        "    if mtype == \"efficientnet\":\n",
        "        model = EfficientNetSquareClassifier(num_classes=num_classes, dropout=drop)\n",
        "    else:\n",
        "        model = SquareClassifier(num_classes=num_classes, dropout=drop)\n",
        "\n",
        "    incompatible = model.load_state_dict(sd, strict=False)\n",
        "    print(f\"[{os.path.basename(path)}] model_guess={mtype} | missing={len(incompatible.missing_keys)} unexpected={len(incompatible.unexpected_keys)}\")\n",
        "    return model.to(DEVICE).eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ZW7G6pNdB1OX",
      "metadata": {
        "id": "ZW7G6pNdB1OX"
      },
      "outputs": [],
      "source": [
        "def build_transforms(train: bool, image_size: int = 96):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(image_size, image_size),\n",
        "            A.RandomBrightnessContrast(p=0.15),\n",
        "            A.GaussNoise(p=0.10),\n",
        "            A.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(image_size, image_size),\n",
        "            A.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "TF_EVAL = build_transforms(train=False, image_size=96)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "mB6O6LN4EjEG",
      "metadata": {
        "id": "mB6O6LN4EjEG"
      },
      "outputs": [],
      "source": [
        "def normalize_line(rho, theta):\n",
        "    if rho < 0:\n",
        "        rho = -rho\n",
        "        theta = (theta + np.pi) % np.pi\n",
        "    return float(rho), float(theta)\n",
        "\n",
        "def extract_grid_masks(gray):\n",
        "    g = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    bw = cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                              cv2.THRESH_BINARY_INV, 21, 5)\n",
        "    H, W = bw.shape\n",
        "    bw2 = cv2.morphologyEx(bw, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (3,3)), iterations=1)\n",
        "    h_len = max(25, W // 14); v_len = max(25, H // 14)\n",
        "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (h_len, 1))\n",
        "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, v_len))\n",
        "    h_mask = cv2.dilate(cv2.erode(bw2, h_kernel, iterations=1), h_kernel, iterations=2)\n",
        "    v_mask = cv2.dilate(cv2.erode(bw2, v_kernel, iterations=1), v_kernel, iterations=2)\n",
        "    return h_mask, v_mask\n",
        "\n",
        "def hough_mask_lines(mask, is_horizontal):\n",
        "    linesP = cv2.HoughLinesP(mask, rho=1, theta=np.pi/180, threshold=50,\n",
        "                             minLineLength=40, maxLineGap=30)\n",
        "    if linesP is None:\n",
        "        return np.zeros((0,2), dtype=np.float32)\n",
        "    out = []\n",
        "    for x1,y1,x2,y2 in linesP[:,0]:\n",
        "        dx, dy = (x2-x1), (y2-y1)\n",
        "        ang = abs(math.degrees(math.atan2(dy, dx)))\n",
        "        if is_horizontal:\n",
        "            if ang > 10 and ang < 170:\n",
        "                continue\n",
        "            theta = np.pi/2\n",
        "        else:\n",
        "            if abs(ang - 90) > 10:\n",
        "                continue\n",
        "            theta = 0\n",
        "        rho = x1*math.cos(theta) + y1*math.sin(theta)\n",
        "        out.append(normalize_line(rho, theta))\n",
        "    return np.array(out, dtype=np.float32)\n",
        "\n",
        "def cluster_to_9_lines(lines):\n",
        "    if len(lines) < 20:\n",
        "        raise RuntimeError(f\"Too few candidate lines: {len(lines)}\")\n",
        "    L = np.array([normalize_line(r,t) for r,t in lines], dtype=np.float32)\n",
        "    rhos = L[:,0].reshape(-1,1)\n",
        "    km = KMeans(n_clusters=9, n_init=\"auto\", random_state=0).fit(rhos)\n",
        "    labels = km.labels_\n",
        "    reps = []\n",
        "    for k in range(9):\n",
        "        group = L[labels == k]\n",
        "        reps.append((float(np.median(group[:,0])), float(np.mean(group[:,1]))))\n",
        "    reps.sort(key=lambda x: x[0])\n",
        "    return reps\n",
        "\n",
        "def x_at_y(line, y):\n",
        "    rho, t = line\n",
        "    c, s = math.cos(t), math.sin(t)\n",
        "    if abs(c) < 1e-9:\n",
        "        return None\n",
        "    return (rho - y*s) / c\n",
        "\n",
        "def y_at_x(line, x):\n",
        "    rho, t = line\n",
        "    c, s = math.cos(t), math.sin(t)\n",
        "    if abs(s) < 1e-9:\n",
        "        return None\n",
        "    return (rho - x*c) / s\n",
        "\n",
        "def sort_vertical_lines_left_to_right(v_lines, img_h):\n",
        "    ymid = img_h / 2.0\n",
        "    scored = []\n",
        "    for line in v_lines:\n",
        "        xv = x_at_y(line, ymid)\n",
        "        if xv is not None and np.isfinite(xv):\n",
        "            scored.append((xv, line))\n",
        "    scored.sort(key=lambda z: z[0])\n",
        "    return [l for _, l in scored]\n",
        "\n",
        "def sort_horizontal_lines_top_to_bottom(h_lines, img_w):\n",
        "    xmid = img_w / 2.0\n",
        "    scored = []\n",
        "    for line in h_lines:\n",
        "        yh = y_at_x(line, xmid)\n",
        "        if yh is not None and np.isfinite(yh):\n",
        "            scored.append((yh, line))\n",
        "    scored.sort(key=lambda z: z[0])\n",
        "    return [l for _, l in scored]\n",
        "\n",
        "def intersect(l1, l2):\n",
        "    rho1, th1 = l1; rho2, th2 = l2\n",
        "    A = np.array([[math.cos(th1), math.sin(th1)],\n",
        "                  [math.cos(th2), math.sin(th2)]], dtype=np.float64)\n",
        "    b = np.array([rho1, rho2], dtype=np.float64)\n",
        "    if abs(np.linalg.det(A)) < 1e-10:\n",
        "        return None\n",
        "    x, y = np.linalg.solve(A, b)\n",
        "    if not (np.isfinite(x) and np.isfinite(y)):\n",
        "        return None\n",
        "    return np.array([x,y], dtype=np.float64)\n",
        "\n",
        "def _fit_homography_from_9x9_lines(gray, board_px=512):\n",
        "    Himg, Wimg = gray.shape[:2]\n",
        "    h_mask, v_mask = extract_grid_masks(gray)\n",
        "    h_candidates = hough_mask_lines(h_mask, True)\n",
        "    v_candidates = hough_mask_lines(v_mask, False)\n",
        "    if len(h_candidates) < 9 or len(v_candidates) < 9:\n",
        "        return None\n",
        "    h9 = sort_horizontal_lines_top_to_bottom(cluster_to_9_lines(h_candidates), Wimg)\n",
        "    v9 = sort_vertical_lines_left_to_right(cluster_to_9_lines(v_candidates), Himg)\n",
        "    src_pts, dst_pts = [], []\n",
        "    for i, h in enumerate(h9):\n",
        "        for j, v in enumerate(v9):\n",
        "            p = intersect(h, v)\n",
        "            if p is None:\n",
        "                continue\n",
        "            x,y = p\n",
        "            if x < -0.02*Wimg or x > 1.02*Wimg or y < -0.02*Himg or y > 1.02*Himg:\n",
        "                continue\n",
        "            src_pts.append([x,y]); dst_pts.append([j,i])\n",
        "    src_pts = np.asarray(src_pts, np.float32)\n",
        "    dst_pts = np.asarray(dst_pts, np.float32)\n",
        "    if len(src_pts) < 70:\n",
        "        return None\n",
        "    H_grid, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, ransacReprojThreshold=1.5)\n",
        "    if H_grid is None:\n",
        "        return None\n",
        "    S = np.array([[board_px/8.0, 0, 0],\n",
        "                  [0, board_px/8.0, 0],\n",
        "                  [0, 0, 1]], dtype=np.float64)\n",
        "    return S @ H_grid\n",
        "\n",
        "def preprocess_board_real(img_bgr, out_size=512, fallback=True):\n",
        "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    H_px = _fit_homography_from_9x9_lines(gray, board_px=out_size)\n",
        "    if H_px is not None:\n",
        "        return cv2.warpPerspective(img_bgr, H_px, (out_size, out_size)), {\"method\":\"hough_grid\"}\n",
        "    if fallback:\n",
        "        h,w = img_bgr.shape[:2]\n",
        "        s = min(h,w)\n",
        "        crop = img_bgr[(h-s)//2:(h+s)//2, (w-s)//2:(w+s)//2].copy()\n",
        "        return cv2.resize(crop, (out_size,out_size), interpolation=cv2.INTER_AREA), {\"method\":\"fallback_center\"}\n",
        "    return cv2.resize(img_bgr, (out_size,out_size)), {\"method\":\"failed\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ggAOV0YHB1OX",
      "metadata": {
        "id": "ggAOV0YHB1OX"
      },
      "outputs": [],
      "source": [
        "def crop_context_square_from_board(board_bgr, r, c, k=1.6, out_size=96):\n",
        "    S = board_bgr.shape[0]\n",
        "    sq = S / 8.0\n",
        "    cx = (c + 0.5) * sq\n",
        "    cy = (r + 0.5) * sq\n",
        "    side = float(k) * float(sq)\n",
        "    half = 0.5 * side\n",
        "    xa = int(round(cx - half)); xb = int(round(cx + half))\n",
        "    ya = int(round(cy - half)); yb = int(round(cy + half))\n",
        "    xa = max(0, min(S-2, xa)); ya = max(0, min(S-2, ya))\n",
        "    xb = max(xa+1, min(S-1, xb)); yb = max(ya+1, min(S-1, yb))\n",
        "    patch = board_bgr[ya:yb, xa:xb]\n",
        "    interp = cv2.INTER_CUBIC if out_size > max(patch.shape[:2]) else cv2.INTER_AREA\n",
        "    return cv2.resize(patch, (out_size,out_size), interpolation=interp)\n",
        "\n",
        "def extract_64_cubes(board_bgr, cube_size=96, k=1.6):\n",
        "    return np.stack([crop_context_square_from_board(board_bgr, r, c, k=k, out_size=cube_size)\n",
        "                     for r in range(8) for c in range(8)], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "_u_gVh8KHjqq",
      "metadata": {
        "id": "_u_gVh8KHjqq"
      },
      "outputs": [],
      "source": [
        "UNICODE_PIECES = {\n",
        "    \"wP\": \"♙\", \"wN\": \"♘\", \"wB\": \"♗\", \"wR\": \"♖\", \"wQ\": \"♕\", \"wK\": \"♔\",\n",
        "    \"bP\": \"♟\", \"bN\": \"♞\", \"bB\": \"♝\", \"bR\": \"♜\", \"bQ\": \"♛\", \"bK\": \"♚\",\n",
        "    \"empty\": \"\"\n",
        "}\n",
        "\n",
        "def render_grid_image(grid, square_px=160, font_path=None):\n",
        "    \"\"\"\n",
        "    grid: (8,8) ints -> class index into CLASSES\n",
        "    square_px: make bigger to see clearly\n",
        "    font_path: support chess symbols\n",
        "    \"\"\"\n",
        "    assert font_path is not None, \"Pass font_path.\"\n",
        "\n",
        "    img = Image.new(\"RGB\", (8*square_px, 8*square_px), \"white\")\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    font = ImageFont.truetype(font_path, int(square_px * 0.82))\n",
        "\n",
        "    for r in range(8):\n",
        "        for c in range(8):\n",
        "            x0, y0 = c*square_px, r*square_px\n",
        "            x1, y1 = x0 + square_px, y0 + square_px\n",
        "\n",
        "            light = (240, 217, 181)\n",
        "            dark  = (181, 136,  99)\n",
        "            draw.rectangle([x0, y0, x1, y1], fill=(light if (r+c)%2==0 else dark))\n",
        "\n",
        "            cls = CLASSES[int(grid[r, c])]\n",
        "            sym = UNICODE_PIECES.get(cls, \"\")\n",
        "\n",
        "            if sym:\n",
        "                bbox = draw.textbbox((0,0), sym, font=font)\n",
        "                w = bbox[2] - bbox[0]\n",
        "                h = bbox[3] - bbox[1]\n",
        "                draw.text(\n",
        "                    (x0 + (square_px - w)//2, y0 + (square_px - h)//2 - int(square_px*0.05)),\n",
        "                    sym,\n",
        "                    fill=(0,0,0),\n",
        "                    font=font\n",
        "                )\n",
        "    return np.array(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "h2_UutkwIqeS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2_UutkwIqeS",
        "outputId": "c147c88d-9c00-40ad-d542-7a3820ecff0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 0 Jan 20 17:22 /content/DejaVuSans.ttf\n"
          ]
        }
      ],
      "source": [
        "!wget -q https://github.com/dejavu-fonts/dejavu-fonts/raw/master/ttf/DejaVuSans.ttf -O /content/DejaVuSans.ttf\n",
        "!ls -l /content/DejaVuSans.ttf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ZA3860UVJKBk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA3860UVJKBk",
        "outputId": "ffe5ffeb-0320-4e84-8f75-27d544e402c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -y >/dev/null\n",
        "!apt-get install -y fonts-dejavu-core >/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "D3-JPbhgT3Ta",
      "metadata": {
        "id": "D3-JPbhgT3Ta"
      },
      "outputs": [],
      "source": [
        "def show_board_with_grid(board_bgr, title=\"Warped board + grid\"):\n",
        "    h, w = board_bgr.shape[:2]\n",
        "    assert h == w, f\"Board not square: {h}x{w}. Fix warp/resize to (N,N).\"\n",
        "    S = h\n",
        "    step = S / 8.0\n",
        "\n",
        "    vis = board_bgr.copy()\n",
        "\n",
        "    for i in range(9):\n",
        "        x = int(round(i * step))\n",
        "        y = int(round(i * step))\n",
        "        cv2.line(vis, (x, 0), (x, S-1), (0, 255, 0), 1)\n",
        "        cv2.line(vis, (0, y), (S-1, y), (0, 255, 0), 1)\n",
        "\n",
        "    vis_rgb = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(vis_rgb)\n",
        "    plt.title(title)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ChE56cLOT6rJ",
      "metadata": {
        "id": "ChE56cLOT6rJ"
      },
      "outputs": [],
      "source": [
        "def show_crops_mosaic(crops_bgr, title=\"64 crops (8x8)\"):\n",
        "    assert len(crops_bgr) == 64\n",
        "    crops_rgb = [cv2.cvtColor(p, cv2.COLOR_BGR2RGB) for p in crops_bgr]\n",
        "\n",
        "    fig, axes = plt.subplots(8, 8, figsize=(10, 10))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(crops_rgb[i])\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "Hh3hjwCtT8Xg",
      "metadata": {
        "id": "Hh3hjwCtT8Xg"
      },
      "outputs": [],
      "source": [
        "files = \"abcdefgh\"\n",
        "\n",
        "def idx_from_square(square: str) -> int:\n",
        "    f = files.index(square[0].lower())\n",
        "    r = int(square[1]) - 1\n",
        "    return (7 - r) * 8 + f\n",
        "\n",
        "def show_square_crop(crops_bgr, square: str):\n",
        "    i = idx_from_square(square)\n",
        "    img_rgb = cv2.cvtColor(crops_bgr[i], cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(3,3))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title(f\"{square} (idx={i})\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import uuid\n",
        "from google.colab import files\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "print(\"Step 1: Upload ONE checkpoint .pt (best_train.pt)\")\n",
        "uploaded_pt = files.upload()\n",
        "assert len(uploaded_pt) == 1, \"Please upload exactly ONE .pt file.\"\n",
        "ckpt_name, ckpt_bytes = next(iter(uploaded_pt.items()))\n",
        "\n",
        "if not ckpt_name.endswith('.pt') and not ckpt_name.endswith('.pth'):\n",
        "    raise ValueError(\"Error: Please upload a .pt file.\")\n",
        "\n",
        "ckpt_path = os.path.join(\"/content\", ckpt_name)\n",
        "with open(ckpt_path, \"wb\") as f:\n",
        "    f.write(ckpt_bytes)\n",
        "print(f\"Checkpoint saved: {ckpt_path}\")\n",
        "\n",
        "CLASSES = ['empty', 'wP', 'wN', 'wB', 'wR', 'wQ', 'wK', 'bP', 'bN', 'bB', 'bR', 'bQ', 'bK']\n",
        "\n",
        "try:\n",
        "    model = load_checkpoint_flexible(ckpt_path, num_classes=len(CLASSES)).to(DEVICE).eval()\n",
        "    print(f\"Model loaded on {DEVICE}\")\n",
        "except NameError:\n",
        "    print(\"Error: Helper functions (load_checkpoint_flexible) not defined. Run previous cells.\")\n",
        "    raise\n",
        "CLASS_MAPPING = torch.tensor([12, 0, 2, 3, 1, 4, 5, 6, 8, 9, 7, 10, 11], dtype=torch.int64)\n",
        "\n",
        "UNICODE_PIECES = {\n",
        "    'wP': '♙', 'wR': '♖', 'wN': '♘', 'wB': '♗', 'wQ': '♕', 'wK': '♔',\n",
        "    'bP': '♟', 'bR': '♜', 'bN': '♞', 'bB': '♝', 'bQ': '♛', 'bK': '♚',\n",
        "    'empty': ''\n",
        "}\n",
        "\n",
        "def get_fen_from_preds(preds_cpu):\n",
        "    \"\"\"Generates FEN string from predictions\"\"\"\n",
        "    grid = preds_cpu.view(8, 8).numpy()\n",
        "    rows = []\n",
        "    for r in range(8):\n",
        "        empties = 0\n",
        "        row_str = []\n",
        "        for c in range(8):\n",
        "            cls_idx = int(grid[r, c])\n",
        "            cls_name = CLASSES[cls_idx]\n",
        "            if cls_name == 'empty':\n",
        "                empties += 1\n",
        "            else:\n",
        "                if empties > 0:\n",
        "                    row_str.append(str(empties))\n",
        "                    empties = 0\n",
        "                piece_char = cls_name[1]\n",
        "                if cls_name.startswith('w'):\n",
        "                    row_str.append(piece_char.upper())\n",
        "                else:\n",
        "                    row_str.append(piece_char.lower())\n",
        "        if empties > 0:\n",
        "            row_str.append(str(empties))\n",
        "        rows.append(\"\".join(row_str))\n",
        "    return \"/\".join(rows)\n",
        "\n",
        "def save_side_by_side(image_rgb, pred_tensor_internal, save_dir=\"./results\"):\n",
        "    \"\"\"\n",
        "    Saves: Left=Input, Right=Rendered Grid (using render_grid_image)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    filename = os.path.join(save_dir, f\"pred_{uuid.uuid4().hex[:8]}.png\")\n",
        "\n",
        "    font_path = \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\"\n",
        "    if not os.path.exists(font_path):\n",
        "        font_path = \"arial.ttf\"\n",
        "\n",
        "    board_img = render_grid_image(pred_tensor_internal.cpu().numpy(), square_px=100, font_path=font_path)\n",
        "    fen = get_fen_from_preds(pred_tensor_internal.cpu())\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    ax[0].imshow(image_rgb)\n",
        "    ax[0].set_title(\"Input Image\")\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    ax[1].imshow(board_img)\n",
        "    ax[1].set_title(f\"Output FEN:\\n{fen}\", fontsize=10)\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename)\n",
        "    plt.close(fig)\n",
        "    return filename\n",
        "\n",
        "def predict_board(image: np.ndarray) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Predicts board state, saves result using render_grid_image, returns Tensor(8,8).\n",
        "    \"\"\"\n",
        "    img_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    board_bgr, _ = preprocess_board_real(img_bgr, out_size=512, fallback=True)\n",
        "    cubes = extract_64_cubes(board_bgr, cube_size=96, k=1.6)\n",
        "\n",
        "    cubes_rgb = np.stack([cv2.cvtColor(p, cv2.COLOR_BGR2RGB) for p in cubes], axis=0)\n",
        "    batch_tensors = torch.stack([TF_EVAL(image=cubes_rgb[i])[\"image\"] for i in range(64)], dim=0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(batch_tensors)\n",
        "        preds_internal = torch.argmax(logits, dim=1)\n",
        "    save_side_by_side(image, preds_internal.view(8,8))\n",
        "    preds_submission = CLASS_MAPPING[preds_internal.cpu()]\n",
        "    output_tensor = preds_submission.view(8, 8)\n",
        "\n",
        "    return output_tensor\n",
        "\n",
        "print(\"\\nStep 2: Upload images\")\n",
        "uploaded_imgs = files.upload()\n",
        "\n",
        "for img_name, img_bytes in uploaded_imgs.items():\n",
        "    print(f\"\\nProcessing {img_name}...\")\n",
        "\n",
        "    nparr = np.frombuffer(img_bytes, np.uint8)\n",
        "    img_bgr = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "    if img_bgr is None: continue\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    try:\n",
        "        result_tensor = predict_board(img_rgb)\n",
        "        print(\"Example Output\")\n",
        "        print(result_tensor)\n",
        "        print(\"Visualization saved to ./results folder.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "BBkW6sQj_TdQ",
        "outputId": "1537138d-705b-4e49-f88f-c65e310662bb"
      },
      "id": "BBkW6sQj_TdQ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Upload ONE checkpoint .pt (best_train.pt)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-91b0f919-710a-43a5-b81a-c37ac8f6aefc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-91b0f919-710a-43a5-b81a-c37ac8f6aefc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving best_train.pt to best_train.pt\n",
            "Checkpoint saved: /content/best_train.pt\n",
            "[best_train.pt] model_guess=resnet | missing=0 unexpected=0\n",
            "Model loaded on cuda\n",
            "\n",
            "Step 2: Upload images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3ac9dfb2-de80-47bd-b4fb-fd0c56fcdc14\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3ac9dfb2-de80-47bd-b4fb-fd0c56fcdc14\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving frame_000536.jpg to frame_000536.jpg\n",
            "\n",
            "Processing frame_000536.jpg...\n",
            "Example Output\n",
            "tensor([[12, 12,  6, 11, 12,  6, 12,  7],\n",
            "        [12,  6,  6,  6, 12,  6,  6,  6],\n",
            "        [12, 12, 12, 12, 12, 12, 12, 12],\n",
            "        [12, 12, 12, 12,  6, 12, 12, 12],\n",
            "        [12, 12,  4, 12,  1, 12, 12, 12],\n",
            "        [12, 12,  1, 12, 12, 12, 12, 12],\n",
            "        [ 2,  0, 12,  0, 12,  0,  2,  4],\n",
            "        [ 1,  1,  0,  4,  5, 12, 12, 12]])\n",
            "Visualization saved to ./results folder.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}